{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADA PM2 - Dataset pre-filtering\n",
    "\n",
    "This notebooks aims at pre-filtering the [YouNiverse](https://zenodo.org/records/4650046) dataset to only keep gaming related content. In the detail, we will proceed following the next steps.\n",
    "1. Keep only videos which `category` is `Gaming`.\n",
    "2. Keep only channels which have at least one video in the selected list.\n",
    "3. Keep only time-series for the selected channels.\n",
    "4. Keep only comments for the selected videos.\n",
    "\n",
    "We will export each of the resulting datasets in a separate `.tsv` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import tqdm\n",
    "import json\n",
    "\n",
    "ORIGINAL_PATH = {\n",
    "    \"videos\": \"../data/youniverse/original/yt_metadata_en.jsonl\",\n",
    "    \"channels\": \"../data/youniverse/original/df_channels_en.tsv\",\n",
    "    \"timeseries\": \"../data/youniverse/original/df_timeseries_en.tsv\",\n",
    "    \"comments\": \"../data/youniverse/original/youtube_comments.tsv\"\n",
    "}\n",
    "\n",
    "FILTERED_PATH = {\n",
    "    \"videos\": \"../data/youniverse/filtered/gaming_videos.tsv\",\n",
    "    \"channels\": \"../data/youniverse/filtered/gaming_channels.tsv\",\n",
    "    \"timeseries\": \"../data/youniverse/filtered/gaming_timeseries.tsv\",\n",
    "    \"comments\": \"../data/youniverse/filtered/gaming_comments.tsv\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Videos\n",
    "As a first step, let's simply grasp the first lines of our dataset so as to understand its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 12)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>categories</th><th>channel_id</th><th>crawl_date</th><th>description</th><th>dislike_count</th><th>display_id</th><th>duration</th><th>like_count</th><th>tags</th><th>title</th><th>upload_date</th><th>view_count</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>str</td><td>i64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Film &amp; Animation&quot;</td><td>&quot;UCzWrhkg9eK5I8Bm3HfV-unA&quot;</td><td>&quot;2019-10-31 20:19:26.270363&quot;</td><td>&quot;Lego City Police Lego Firetruc…</td><td>1.0</td><td>&quot;SBqSc91Hn9g&quot;</td><td>1159</td><td>8.0</td><td>&quot;lego city,lego police,lego cit…</td><td>&quot;Lego City Police Lego Firetruc…</td><td>&quot;2016-09-28 00:00:00&quot;</td><td>1057.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 12)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ categorie ┆ channel_i ┆ crawl_dat ┆ descripti ┆ … ┆ tags      ┆ title     ┆ upload_da ┆ view_cou │\n",
       "│ s         ┆ d         ┆ e         ┆ on        ┆   ┆ ---       ┆ ---       ┆ te        ┆ nt       │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ str       ┆ str       ┆ ---       ┆ ---      │\n",
       "│ str       ┆ str       ┆ str       ┆ str       ┆   ┆           ┆           ┆ str       ┆ f64      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ Film &    ┆ UCzWrhkg9 ┆ 2019-10-3 ┆ Lego City ┆ … ┆ lego      ┆ Lego City ┆ 2016-09-2 ┆ 1057.0   │\n",
       "│ Animation ┆ eK5I8Bm3H ┆ 1 20:19:2 ┆ Police    ┆   ┆ city,lego ┆ Police    ┆ 8         ┆          │\n",
       "│           ┆ fV-unA    ┆ 6.270363  ┆ Lego      ┆   ┆ police,le ┆ Lego      ┆ 00:00:00  ┆          │\n",
       "│           ┆           ┆           ┆ Firetruc… ┆   ┆ go cit…   ┆ Firetruc… ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.read_ndjson(ORIGINAL_PATH[\"videos\"], n_rows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we only want to get **gaming videos**, we need to filter out this category from our dataset. At the same time, we filter out the columns that are not relevant for our analysis. According to our understanding of the dataset, we will keep the following columns :\n",
    "- `title` and `tags`, which contain useful information about the video content\n",
    "- `upload_date`, which may be useful to track the link between subjects and periods\n",
    "- `view_count`, `like_count` and `dislike_count`, which are key indicators of the video popularity\n",
    "- `duration`, which may be useful to track trends per video game\n",
    "- `channel_id` and `display_id`, which are useful to link videos to channels and comments\n",
    "\n",
    "We drop the `description` column, as it is too heavy to handle over that many videos. We also drop the `categories` column, which is no longer relevant, as well as the `crawl_date` column which is not usefult for our study. Finally, we fill missing values for `tags` with empty strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\n",
    "    \"categories\",\n",
    "    \"title\",\n",
    "    \"tags\",\n",
    "    \"upload_date\",\n",
    "    \"view_count\",\n",
    "    \"like_count\",\n",
    "    \"dislike_count\",\n",
    "    \"duration\",\n",
    "    \"channel_id\",\n",
    "    \"display_id\",\n",
    "]\n",
    "\n",
    "filtered_gaming_df = (\n",
    "    pl.read_ndjson(ORIGINAL_PATH[\"videos\"])\n",
    "    .select(columns_to_keep)\n",
    "    .filter(pl.col(\"categories\") == \"Gaming\")\n",
    "    .fill_null(\"\")\n",
    "    .drop(\"categories\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can convert our `polar` LazyFrame to a `.tsv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_gaming_df.write_csv(FILTERED_PATH[\"videos\"], separator=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channels\n",
    "\n",
    "Let's see what this dataset looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>category_cc</th><th>join_date</th><th>channel</th><th>name_cc</th><th>subscribers_cc</th><th>videos_cc</th><th>subscriber_rank_sb</th><th>weights</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>i64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Gaming&quot;</td><td>&quot;2010-04-29&quot;</td><td>&quot;UC-lHJZR3Gqxm24_Vd_AJ5Yw&quot;</td><td>&quot;PewDiePie&quot;</td><td>101000000</td><td>3956</td><td>3.0</td><td>2.087</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 8)\n",
       "┌────────────┬────────────┬────────────┬───────────┬────────────┬───────────┬────────────┬─────────┐\n",
       "│ category_c ┆ join_date  ┆ channel    ┆ name_cc   ┆ subscriber ┆ videos_cc ┆ subscriber ┆ weights │\n",
       "│ c          ┆ ---        ┆ ---        ┆ ---       ┆ s_cc       ┆ ---       ┆ _rank_sb   ┆ ---     │\n",
       "│ ---        ┆ str        ┆ str        ┆ str       ┆ ---        ┆ i64       ┆ ---        ┆ f64     │\n",
       "│ str        ┆            ┆            ┆           ┆ i64        ┆           ┆ f64        ┆         │\n",
       "╞════════════╪════════════╪════════════╪═══════════╪════════════╪═══════════╪════════════╪═════════╡\n",
       "│ Gaming     ┆ 2010-04-29 ┆ UC-lHJZR3G ┆ PewDiePie ┆ 101000000  ┆ 3956      ┆ 3.0        ┆ 2.087   │\n",
       "│            ┆            ┆ qxm24_Vd_A ┆           ┆            ┆           ┆            ┆         │\n",
       "│            ┆            ┆ J5Yw       ┆           ┆            ┆           ┆            ┆         │\n",
       "└────────────┴────────────┴────────────┴───────────┴────────────┴───────────┴────────────┴─────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.read_csv(ORIGINAL_PATH[\"channels\"], separator='\\t', n_rows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for our further analysis, we need to keep only the **gaming channels**. Furthermore, the channel ID's and names are needed to identify the channels in the videos dataset. Subscriber and video counts are also mandatory for having statistical insights. Thus, we will keep the following columns:\n",
    "- `channel` is the channel ID to link with the videos dataset, we will rename it to `channel_id`\n",
    "- `name_cc` is the channel name, which more human-readable and will be renamed to `channel_name`\n",
    "- `subscribers_cc` and `videos_cc` are key indicators of the channel popularity\n",
    "\n",
    "Since we only focus on gaming channels, we will filter out the other categories, and supress the `category_cc` column. We will also drop the `join_date`, `subscriber_rank_sb` and `weight_sb` columns, as they are not relevant for our work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_df = pl.read_csv(ORIGINAL_PATH[\"channels\"], separator='\\t')\n",
    "\n",
    "gaming_channels_df = channels_df.filter(pl.col(\"category_cc\") == \"Gaming\").select([\n",
    "    \"channel\",\n",
    "    \"name_cc\",\n",
    "    \"subscribers_cc\",\n",
    "    \"videos_cc\",\n",
    "]).rename({\n",
    "    \"channel\": \"channel_id\",\n",
    "    \"name_cc\": \"channel_name\",\n",
    "    \"subscribers_cc\": \"subscribers\",\n",
    "    \"videos_cc\": \"videos\",\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataframe is approximately **20000 rows-long**. We can now write the filtered dataset to a `tsv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaming_channels_df.write_csv(FILTERED_PATH[\"channels\"], separator='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-series\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next step of pre-filtering is to treat the **time-series** dataset. It contains the time-series of views and subscribers for each channel. Each data point represents the **view and subsciber count** for a given week. Here is what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>channel</th><th>category</th><th>datetime</th><th>views</th><th>delta_views</th><th>subs</th><th>delta_subs</th><th>videos</th><th>delta_videos</th><th>activity</th></tr><tr><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;UCBJuEqXfXTdcPSbGO9qqn1g&quot;</td><td>&quot;Film and Animation&quot;</td><td>&quot;2017-07-03 00:00:00&quot;</td><td>202494.555556</td><td>0.0</td><td>650.222222</td><td>0.0</td><td>5</td><td>0</td><td>3</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 10)\n",
       "┌────────────┬────────────┬────────────┬───────────┬───┬───────────┬────────┬───────────┬──────────┐\n",
       "│ channel    ┆ category   ┆ datetime   ┆ views     ┆ … ┆ delta_sub ┆ videos ┆ delta_vid ┆ activity │\n",
       "│ ---        ┆ ---        ┆ ---        ┆ ---       ┆   ┆ s         ┆ ---    ┆ eos       ┆ ---      │\n",
       "│ str        ┆ str        ┆ str        ┆ f64       ┆   ┆ ---       ┆ i64    ┆ ---       ┆ i64      │\n",
       "│            ┆            ┆            ┆           ┆   ┆ f64       ┆        ┆ i64       ┆          │\n",
       "╞════════════╪════════════╪════════════╪═══════════╪═══╪═══════════╪════════╪═══════════╪══════════╡\n",
       "│ UCBJuEqXfX ┆ Film and   ┆ 2017-07-03 ┆ 202494.55 ┆ … ┆ 0.0       ┆ 5      ┆ 0         ┆ 3        │\n",
       "│ TdcPSbGO9q ┆ Animation  ┆ 00:00:00   ┆ 5556      ┆   ┆           ┆        ┆           ┆          │\n",
       "│ qn1g       ┆            ┆            ┆           ┆   ┆           ┆        ┆           ┆          │\n",
       "└────────────┴────────────┴────────────┴───────────┴───┴───────────┴────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.read_csv(ORIGINAL_PATH[\"timeseries\"], separator='\\t', n_rows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our work, we will keep the following columns, only for the **gaming** channels:\n",
    "- `channel` to link with the videos and channels datasets, it will be renamed to `channel_id`\n",
    "- `datetime` to track the time of the data point\t\n",
    "- `views`, `subs` and `videos` to track the global statistics of the channel\n",
    "- `delta_views`, `delta_subs` and `delta_videos` to track the evolution of the channel\n",
    "\n",
    "However, the columns we are not interested are `category` because it will always be **Gaming**, and `activity` which represents the number of videos uploaded in the last 15 days, and we suppress them.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_df = pl.read_csv(ORIGINAL_PATH[\"timeseries\"], separator=\"\\t\")\n",
    "\n",
    "filtered_timeseries_df = timeseries_df.filter(pl.col(\"category\") == \"Gaming\").select([\n",
    "    \"channel\",\n",
    "    \"datetime\",\n",
    "    \"views\",\n",
    "    \"delta_views\",\n",
    "    \"subs\",\n",
    "    \"delta_subs\",\n",
    "    \"videos\",\n",
    "    \"delta_videos\"\n",
    "]).rename({\"channel\": \"channel_id\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the same reasons as mentioned above, we will write this dataset to a `.tsv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_timeseries_df.write_csv(FILTERED_PATH[\"timeseries\"], separator=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments\n",
    "\n",
    "Now is the time to handle the **biggest** dataset of our work: the **comments**. Here is what a comment looks like in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>author</th><th>video_id</th></tr><tr><td>i64</td><td>str</td></tr></thead><tbody><tr><td>2</td><td>&quot;9pQILRT42Cg&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 2)\n",
       "┌────────┬─────────────┐\n",
       "│ author ┆ video_id    │\n",
       "│ ---    ┆ ---         │\n",
       "│ i64    ┆ str         │\n",
       "╞════════╪═════════════╡\n",
       "│ 2      ┆ 9pQILRT42Cg │\n",
       "└────────┴─────────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.read_csv(ORIGINAL_PATH[\"comments\"], separator='\\t', n_rows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The work that needs to be done is to filter out the comments that are **not related** to gaming videos. To do so, we thought of having a set containing all the **gaming video IDs**, and checking for each comment if its video ID is in this list. If it is, we keep the comment, otherwise we drop it.\n",
    "\n",
    "The columns that we will keep are:\n",
    "- `author`, which is the **author's ID**, to ensure we keep track of which user commented on which video\n",
    "- `video_id`, which is the **video's ID**, to link the comments to the videos\n",
    "\n",
    "The `likes` and `replies` columns are not needed for our graphs' generations so we will drop them.\n",
    "\n",
    "Firstly, we generate the set of **gaming video IDs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaming_display_ids = set(filtered_gaming_df.to_pandas()[\"display_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then filter out the comments that are **not related** to gaming videos. Finally, we save the filtered dataset to a `.tsv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pl.scan_csv(ORIGINAL_PATH[\"comments\"], sep='\\t', has_header=True).select([\"author\", \"video_id\"])\n",
    "gaming_comments_df = comments.filter(pl.col(\"video_id\").is_in(gaming_display_ids))\n",
    "\n",
    "gaming_comments_df.write_csv(FILTERED_PATH[\"comments\"], separator=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada-pm2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
